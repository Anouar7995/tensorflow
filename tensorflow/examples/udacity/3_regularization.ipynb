{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 3\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb`, you trained a logistic regression and a neural network model.\n",
    "\n",
    "The goal of this assignment is to explore regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HrCK6e17WzV"
   },
   "source": [
    "First reload the data we generated in _notmist.ipynb_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11777,
     "status": "ok",
     "timestamp": 1449849322348,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "e03576f1-ebbe-4838-c388-f1777bcc9873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (179817, 28, 28) (179817,)\n",
      "Validation set (62958, 28, 28) (62958,)\n",
      "Test set (17540, 28, 28) (17540,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'cleanMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_index:  [133388  80279 127173  23804  69185]\n",
      "sample labels: [ 0.  4.  3.  3.  4.]\n",
      "sample_index:  [165821  83940 101541 124741 123204]\n",
      "sample labels: [ 6.  3.  6.  7.  8.]\n",
      "sample_index:  [179046   5662  97627  40029 106092]\n",
      "sample labels: [ 3.  6.  0.  0.  2.]\n",
      "sample_index:  [140344  63140 128448   1709 114665]\n",
      "sample labels: [ 4.  8.  1.  6.  5.]\n",
      "sample_index:  [116396 104294 168131  81362  40416]\n",
      "sample labels: [ 4.  3.  6.  0.  5.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVsAAAD/CAYAAABfNXWhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxQ/8D/8g3AZ7Ej/BAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x120b38d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def visual_confirmation(train_dataset, train_labels):\n",
    "     fig, plt_axes_arr=plt.subplots(5, 5)\n",
    "     for i in range(5):\n",
    "         sample_index = np.random.choice(train_dataset.shape[0],5)\n",
    "         print(\"sample_index: \", sample_index)\n",
    "         print(\"sample labels:\", train_labels[sample_index])\n",
    "         for j,idx in enumerate(sample_index):\n",
    "             plt_axes_arr[i,j].imshow(train_dataset[idx],cmap='Greys')\n",
    "             plt_axes_arr[i,j].axis('off')\n",
    "     plt.show()\n",
    "visual_confirmation(train_dataset,train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "- data as a flat matrix,\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11728,
     "status": "ok",
     "timestamp": 1449849322356,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "3f8996ee-3574-4f44-c953-5c8a04636582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (179817, 784) (179817, 10)\n",
      "Validation set (62958, 784) (62958, 10)\n",
      "Test set (17540, 784) (17540, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "  # Map 2 to [0.0, 1.0, 0.0 ...], 3 to [0.0, 0.0, 1.0 ...]\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "RajPLaL_ZW6w"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgLbUAQ1CW-1"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "Introduce and tune L2 regularization for both logistic and neural network models. Remember that L2 amounts to adding a penalty on the norm of the weights to the loss. In TensorFlow, you can compute the L2 loss for a tensor `t` using `nn.l2_loss(t)`. The right amount of regularization should improve your validation / test accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# With gradient descent training, even this much data is prohibitive.\n",
    "# Subset the training data for faster turnaround.\n",
    "train_subset = 179000\n",
    "beta=0.005\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  # Load the training, validation and test data into constants that are\n",
    "  # attached to the graph.\n",
    "  tf_train_dataset = tf.constant(train_dataset[:train_subset, :])\n",
    "  tf_train_labels = tf.constant(train_labels[:train_subset])\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  # These are the parameters that we are going to be training. The weight\n",
    "  # matrix will be initialized using random valued following a (truncated)\n",
    "  # normal distribution. The biases get initialized to zero.\n",
    "  weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "  biases = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  # We multiply the inputs with the weight matrix, and add biases. We compute\n",
    "  # the softmax and cross-entropy (it's one operation in TensorFlow, because\n",
    "  # it's very common, and it can be optimized). We take the average of this\n",
    "  # cross-entropy across all training examples: that's our loss.\n",
    "  logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "  loss = loss + beta*tf.nn.l2_loss(weights, name=None)\n",
    "  \n",
    "  # Optimizer.\n",
    "  # We are going to find the minimum of this loss using gradient descent.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  # These are not part of training, but merely here so that we can report\n",
    "  # accuracy figures as we train.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_steps = 801\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  # This is a one-time operation which ensures the parameters get initialized as\n",
    "  # we described in the graph: random weights for the matrix, zeros for the\n",
    "  # biases. \n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    # Run the computations. We tell .run() that we want to run the optimizer,\n",
    "    # and get the loss value and the training predictions returned as numpy\n",
    "    # arrays.\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "    if (step % 100 == 0):\n",
    "      print('Loss at step %d: %f' % (step, l))\n",
    "      print('Training accuracy: %.1f%%' % accuracy(\n",
    "        predictions, train_labels[:train_subset, :]))\n",
    "      # Calling .eval() on valid_prediction is basically like calling run(), but\n",
    "      # just to get that one numpy array. Note that it recomputes all its graph\n",
    "      # dependencies.\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#With RELU\n",
    "batch_size = 512\n",
    "num_nodes=512\n",
    "beta=0.0007\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "    \n",
    "  weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "  biases = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "  weights_0 = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_nodes],stddev=0.1))\n",
    "  biases_0 = tf.Variable(tf.constant(0.02,shape=[512]))\n",
    "  \n",
    "    \n",
    "  weights_1 = tf.Variable(\n",
    "    tf.truncated_normal([num_nodes, num_labels]))\n",
    "  biases_1 = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  logits_train_0 = tf.nn.relu(tf.matmul(tf_train_dataset, weights_0) + biases_0)\n",
    "  logits_train_1 = tf.matmul(logits_train_0, weights_1) + biases_1\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits_train_1, tf_train_labels))\n",
    "  loss = loss + beta*(tf.nn.l2_loss(weights_0, name=None) + tf.nn.l2_loss(weights_1, name=None))\n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits_train_1)\n",
    "\n",
    "  valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul((tf.nn.relu(tf.matmul(tf_valid_dataset, weights_0) + biases_0)), weights_1) + biases_1)\n",
    "  test_prediction = tf.nn.softmax(\n",
    "    tf.matmul((tf.nn.relu(tf.matmul(tf_test_dataset, weights_0) + biases_0)), weights_1) + biases_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_steps = 15003\n",
    "\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "na8xX2yHZzNF"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "Let's demonstrate an extreme case of overfitting. Restrict your training data to just a few batches. What happens?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#With RELU\n",
    "batch_size = 16\n",
    "num_nodes=16\n",
    "beta=0.0007\n",
    "train_subset = 16\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "    \n",
    "  weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "  biases = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "  weights_0 = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_nodes],stddev=0.1))\n",
    "  biases_0 = tf.Variable(tf.constant(0.02,shape=[16]))\n",
    "  \n",
    "    \n",
    "  weights_1 = tf.Variable(\n",
    "    tf.truncated_normal([num_nodes, num_labels]))\n",
    "  biases_1 = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  logits_train_0 = tf.nn.relu(tf.matmul(tf_train_dataset, weights_0) + biases_0)\n",
    "  logits_train_1 = tf.matmul(logits_train_0, weights_1) + biases_1\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits_train_1, tf_train_labels))\n",
    "  loss = loss + beta*(tf.nn.l2_loss(weights_0, name=None) + tf.nn.l2_loss(weights_1, name=None))\n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits_train_1)\n",
    "\n",
    "  valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul((tf.nn.relu(tf.matmul(tf_valid_dataset, weights_0) + biases_0)), weights_1) + biases_1)\n",
    "  test_prediction = tf.nn.softmax(\n",
    "    tf.matmul((tf.nn.relu(tf.matmul(tf_test_dataset, weights_0) + biases_0)), weights_1) + biases_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_steps = 10\n",
    "\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 5 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ww3SCBUdlkRc"
   },
   "source": [
    "---\n",
    "Problem 3\n",
    "---------\n",
    "Introduce Dropout on the hidden layer of the neural network. Remember: Dropout should only be introduced during training, not evaluation, otherwise your evaluation results would be stochastic as well. TensorFlow provides `nn.dropout()` for that, but you have to make sure it's only inserted during training.\n",
    "\n",
    "What happens to our extreme overfitting case?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#With RELU\n",
    "batch_size = 512\n",
    "num_nodes=512\n",
    "\n",
    "train_subset = 179000\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "    \n",
    "  weights = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_labels]))\n",
    "  biases = tf.Variable(tf.zeros([num_labels]))\n",
    "    \n",
    "  weights_0 = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_nodes],stddev=0.001))\n",
    "  biases_0 = tf.Variable(tf.constant(0.01,shape=[512]))\n",
    "  \n",
    "    \n",
    "  weights_1 = tf.Variable(\n",
    "    tf.truncated_normal([num_nodes, num_labels]))\n",
    "  biases_1 = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  logits_train_0 = tf.nn.relu(tf.matmul(tf_train_dataset, weights_0) + biases_0)\n",
    "  logits_train_1 = tf.nn.dropout(tf.matmul(logits_train_0, weights_1) + biases_1,0.5)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits_train_1, tf_train_labels))\n",
    "  \n",
    "    \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.05).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits_train_1)\n",
    "\n",
    "  valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul((tf.nn.relu(tf.matmul(tf_valid_dataset, weights_0) + biases_0)), weights_1) + biases_1)\n",
    "  test_prediction = tf.nn.softmax(\n",
    "    tf.matmul((tf.nn.relu(tf.matmul(tf_test_dataset, weights_0) + biases_0)), weights_1) + biases_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 2.401596\n",
      "Minibatch accuracy: 11.5%\n",
      "Validation accuracy: 56.7%\n",
      "Minibatch loss at step 1000: 1.169355\n",
      "Minibatch accuracy: 51.4%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 2000: 1.030051\n",
      "Minibatch accuracy: 59.8%\n",
      "Validation accuracy: 88.6%\n",
      "Minibatch loss at step 3000: 1.144823\n",
      "Minibatch accuracy: 52.3%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 4000: 1.105938\n",
      "Minibatch accuracy: 53.7%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 5000: 0.963793\n",
      "Minibatch accuracy: 58.6%\n",
      "Validation accuracy: 89.6%\n",
      "Minibatch loss at step 6000: 1.080467\n",
      "Minibatch accuracy: 52.0%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 7000: 1.040301\n",
      "Minibatch accuracy: 54.7%\n",
      "Validation accuracy: 89.7%\n",
      "Minibatch loss at step 8000: 0.955563\n",
      "Minibatch accuracy: 57.2%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 9000: 0.991925\n",
      "Minibatch accuracy: 57.2%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 10000: 0.992367\n",
      "Minibatch accuracy: 56.1%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 11000: 0.961237\n",
      "Minibatch accuracy: 55.9%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 12000: 0.954933\n",
      "Minibatch accuracy: 58.8%\n",
      "Validation accuracy: 89.9%\n",
      "Minibatch loss at step 13000: 0.913630\n",
      "Minibatch accuracy: 62.1%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 14000: 0.962505\n",
      "Minibatch accuracy: 54.9%\n",
      "Validation accuracy: 90.1%\n",
      "Minibatch loss at step 15000: 0.886816\n",
      "Minibatch accuracy: 59.4%\n",
      "Validation accuracy: 90.0%\n",
      "Minibatch loss at step 16000: 0.966060\n",
      "Minibatch accuracy: 54.5%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 17000: 0.849609\n",
      "Minibatch accuracy: 64.6%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 18000: 0.845595\n",
      "Minibatch accuracy: 61.3%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 19000: 0.917407\n",
      "Minibatch accuracy: 58.4%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 20000: 0.950267\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 90.2%\n",
      "Test accuracy: 95.4%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 20501\n",
    "\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 1000 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-b1hTz3VWZjw"
   },
   "source": [
    "---\n",
    "Problem 4\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a multi-layer model! The best reported test accuracy using a deep network is [97.1%](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html?showComment=1391023266211#c8758720086795711595).\n",
    "\n",
    "One avenue you can explore is to add multiple layers.\n",
    "\n",
    "Another one is to use learning rate decay:\n",
    "\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, ...)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    " \n",
    " ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#With RELU\n",
    "batch_size = 1024\n",
    "num_nodes=1024\n",
    "\n",
    "train_subset = 179000\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "    \n",
    "    \n",
    "  weights_0 = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_nodes],stddev=0.001))\n",
    "  biases_0 = tf.Variable(tf.constant(0.001,shape=[1024]))\n",
    "    \n",
    "  weights_1 = tf.Variable(\n",
    "    tf.truncated_normal([num_nodes, num_nodes],stddev=0.001))\n",
    "  biases_1 = tf.Variable(tf.constant(0.001,shape=[1024]))\n",
    "  \n",
    "    \n",
    "  weights_2 = tf.Variable(\n",
    "    tf.truncated_normal([num_nodes, num_labels]))\n",
    "  biases_2 = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  logits_train_0 = tf.nn.relu(tf.matmul(tf_train_dataset, weights_0) + biases_0)\n",
    "  logits_train_1 = tf.nn.dropout(tf.nn.relu(tf.matmul(logits_train_0, weights_1) + biases_1),0.5)\n",
    "  logits_train_2 = tf.nn.dropout(tf.matmul(logits_train_1, weights_2) + biases_2,0.5)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits_train_2, tf_train_labels))\n",
    "  \n",
    "    \n",
    "  # Optimizer.\n",
    "  global_step = tf.Variable(0, trainable=False)\n",
    "  starter_learning_rate = 0.01\n",
    "  learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                           1000, 0.96, staircase=True)\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)\n",
    "  #optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits_train_2)\n",
    "\n",
    "  valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(tf_valid_dataset, weights_0) + biases_0), weights_1) + biases_1), weights_2) + biases_2)\n",
    "    \n",
    "  test_prediction = tf.nn.softmax(\n",
    "    tf.matmul(tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(tf_test_dataset, weights_0) + biases_0), weights_1) + biases_1), weights_2) + biases_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 2.303026\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 10.1%\n",
      "Minibatch loss at step 500: 1.184262\n",
      "Minibatch accuracy: 52.4%\n",
      "Validation accuracy: 84.5%\n",
      "Minibatch loss at step 1000: 1.212629\n",
      "Minibatch accuracy: 51.0%\n",
      "Validation accuracy: 86.2%\n",
      "Minibatch loss at step 1500: 1.186856\n",
      "Minibatch accuracy: 51.9%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 2000: 1.130140\n",
      "Minibatch accuracy: 53.8%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 2500: 1.111419\n",
      "Minibatch accuracy: 53.7%\n",
      "Validation accuracy: 88.5%\n",
      "Minibatch loss at step 3000: 1.125326\n",
      "Minibatch accuracy: 53.1%\n",
      "Validation accuracy: 88.9%\n",
      "Minibatch loss at step 3500: 1.079147\n",
      "Minibatch accuracy: 53.8%\n",
      "Validation accuracy: 89.1%\n",
      "Minibatch loss at step 4000: 1.071803\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 89.5%\n",
      "Minibatch loss at step 4500: 1.115794\n",
      "Minibatch accuracy: 53.6%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 5000: 1.115289\n",
      "Minibatch accuracy: 52.1%\n",
      "Validation accuracy: 89.8%\n",
      "Minibatch loss at step 5500: 1.070388\n",
      "Minibatch accuracy: 53.5%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 6000: 1.031691\n",
      "Minibatch accuracy: 55.9%\n",
      "Validation accuracy: 90.2%\n",
      "Minibatch loss at step 6500: 1.029620\n",
      "Minibatch accuracy: 57.1%\n",
      "Validation accuracy: 90.3%\n",
      "Minibatch loss at step 7000: 1.070380\n",
      "Minibatch accuracy: 55.9%\n",
      "Validation accuracy: 90.4%\n",
      "Minibatch loss at step 7500: 1.014509\n",
      "Minibatch accuracy: 57.1%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 8000: 1.066677\n",
      "Minibatch accuracy: 55.8%\n",
      "Validation accuracy: 90.5%\n",
      "Minibatch loss at step 8500: 1.048389\n",
      "Minibatch accuracy: 53.6%\n",
      "Validation accuracy: 90.7%\n",
      "Minibatch loss at step 9000: 1.055523\n",
      "Minibatch accuracy: 54.0%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 9500: 1.027758\n",
      "Minibatch accuracy: 55.7%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 10000: 1.011470\n",
      "Minibatch accuracy: 55.3%\n",
      "Validation accuracy: 90.8%\n",
      "Minibatch loss at step 10500: 1.022410\n",
      "Minibatch accuracy: 56.0%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 11000: 1.021156\n",
      "Minibatch accuracy: 55.7%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 11500: 1.032212\n",
      "Minibatch accuracy: 54.3%\n",
      "Validation accuracy: 90.9%\n",
      "Minibatch loss at step 12000: 0.973532\n",
      "Minibatch accuracy: 58.9%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 12500: 0.981141\n",
      "Minibatch accuracy: 57.9%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 13000: 0.975890\n",
      "Minibatch accuracy: 56.7%\n",
      "Validation accuracy: 91.0%\n",
      "Minibatch loss at step 13500: 0.919024\n",
      "Minibatch accuracy: 60.1%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 14000: 0.944939\n",
      "Minibatch accuracy: 58.4%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 14500: 0.963967\n",
      "Minibatch accuracy: 56.7%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 15000: 0.965710\n",
      "Minibatch accuracy: 56.7%\n",
      "Validation accuracy: 91.1%\n",
      "Minibatch loss at step 15500: 0.980595\n",
      "Minibatch accuracy: 57.4%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 16000: 1.040803\n",
      "Minibatch accuracy: 55.2%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 16500: 1.003417\n",
      "Minibatch accuracy: 54.5%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 17000: 0.914662\n",
      "Minibatch accuracy: 60.8%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 17500: 0.900186\n",
      "Minibatch accuracy: 60.4%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 18000: 1.003060\n",
      "Minibatch accuracy: 57.2%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 18500: 0.969285\n",
      "Minibatch accuracy: 57.0%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 19000: 1.010309\n",
      "Minibatch accuracy: 55.2%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 19500: 0.990086\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 91.2%\n",
      "Minibatch loss at step 20000: 0.895445\n",
      "Minibatch accuracy: 60.0%\n",
      "Validation accuracy: 91.3%\n",
      "Minibatch loss at step 20500: 0.950349\n",
      "Minibatch accuracy: 56.6%\n",
      "Validation accuracy: 91.3%\n",
      "Test accuracy: 96.1%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 20501\n",
    "\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "ADAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#With RELU\n",
    "batch_size = 1024\n",
    "num_nodes=1024\n",
    "\n",
    "train_subset = 179000\n",
    "\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "    \n",
    "    \n",
    "  weights_0 = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, num_nodes],stddev=0.001))\n",
    "  biases_0 = tf.Variable(tf.constant(0.001,shape=[1024]))\n",
    "    \n",
    "  weights_1 = tf.Variable(\n",
    "    tf.truncated_normal([num_nodes, num_nodes],stddev=0.001))\n",
    "  biases_1 = tf.Variable(tf.constant(0.001,shape=[1024]))\n",
    "  \n",
    "    \n",
    "  weights_2 = tf.Variable(\n",
    "    tf.truncated_normal([num_nodes, num_labels]))\n",
    "  biases_2 = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  logits_train_0 = tf.nn.relu(tf.matmul(tf_train_dataset, weights_0) + biases_0)\n",
    "  logits_train_1 = tf.nn.dropout(tf.nn.relu(tf.matmul(logits_train_0, weights_1) + biases_1),0.5)\n",
    "  logits_train_2 = tf.nn.dropout(tf.matmul(logits_train_1, weights_2) + biases_2,0.5)\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits_train_2, tf_train_labels))\n",
    "  \n",
    "    \n",
    "  # Optimizer.\n",
    "  global_step = tf.Variable(0, trainable=False)\n",
    "  starter_learning_rate = 0.01\n",
    "  learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "                                           1000, 0.96, staircase=True)\n",
    "  #optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)\n",
    "  optimizer=tf.train.AdamOptimizer(learning_rate=0.005, epsilon=1e-06).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits_train_2)\n",
    "\n",
    "  valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(tf_valid_dataset, weights_0) + biases_0), weights_1) + biases_1), weights_2) + biases_2)\n",
    "    \n",
    "  test_prediction = tf.nn.softmax(\n",
    "    tf.matmul(tf.nn.relu(tf.matmul(tf.nn.relu(tf.matmul(tf_test_dataset, weights_0) + biases_0), weights_1) + biases_1), weights_2) + biases_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 2.302207\n",
      "Minibatch accuracy: 10.4%\n",
      "Validation accuracy: 10.1%\n",
      "Minibatch loss at step 500: 1.238723\n",
      "Minibatch accuracy: 49.6%\n",
      "Validation accuracy: 84.8%\n",
      "Minibatch loss at step 1000: 1.161417\n",
      "Minibatch accuracy: 51.7%\n",
      "Validation accuracy: 85.3%\n",
      "Minibatch loss at step 1500: 1.206982\n",
      "Minibatch accuracy: 51.8%\n",
      "Validation accuracy: 85.5%\n",
      "Test accuracy: 91.8%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 1501\n",
    "\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "3_regularization.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
